{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c953153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForMaskedLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import random\n",
    "\n",
    "# 원하는 시드 값으로 설정\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "## 모델 준비\n",
    "model_id = \"beomi/polyglot-ko-12.8b-safetensors\"  # safetensors 컨버팅된 레포\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={'':0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    padding_side=\"left\",\n",
    "    model_max_length=512,    \n",
    ")\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model = model, model_id = './output/SFT_aihub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "prompt_df = pd.read_json('SFT_aihub_eval.json')\n",
    "\n",
    "prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c23484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from utils.prompter import Prompter\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "prompter = Prompter()\n",
    "\n",
    "source, target = [], []\n",
    "for i in range(len(prompt_df)):\n",
    "    source.append(prompt_df['input'][i])\n",
    "    target.append(prompt_df['output'][i])\n",
    "    \n",
    "\n",
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5cf80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../ngram/uni_model.pkl', 'rb') as f:\n",
    "    uni_model = pickle.load(f)\n",
    "    \n",
    "with open('../ngram/bi_model.pkl', 'rb') as f:\n",
    "    bi_model = pickle.load(f)\n",
    "    \n",
    "def load_ngram_counts(filename):\n",
    "    \"\"\"\n",
    "    Load bigram and trigram counts from a .pkl file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        bigram_counts, trigram_counts = pickle.load(f)\n",
    "    return bigram_counts, trigram_counts\n",
    "\n",
    "def calculate_trigram_probabilities(sentence, bigram_counts, trigram_counts):\n",
    "    \"\"\"\n",
    "    Calculate trigram probabilities for a given sentence using loaded bigram and trigram counts.\n",
    "    \"\"\"\n",
    "    # 토큰화된 문장 준비\n",
    "    words = sentence.split()\n",
    "    trigram_probabilities = 0\n",
    "\n",
    "    for i in range(len(words) - 2):\n",
    "        trigram = (words[i], words[i + 1], words[i + 2])\n",
    "        bigram = (words[i], words[i + 1])\n",
    "\n",
    "        # 바이그램과 트라이그램 빈도를 사용하여 확률 계산\n",
    "        if trigram in trigram_counts and bigram in bigram_counts:\n",
    "#             trigram_probabilities[trigram] = trigram_counts[trigram] / bigram_counts[bigram]\n",
    "            trigram_probabilities += trigram_counts[trigram] / bigram_counts[bigram]\n",
    "#         else:\n",
    "#             trigram_probabilities[trigram] = 0\n",
    "\n",
    "    return trigram_probabilities\n",
    "\n",
    "bigram_counts, trigram_counts = load_ngram_counts('../ngram/tri_model.pkl')\n",
    "probs = calculate_trigram_probabilities('한국 정부도 알고 있다', bigram_counts, trigram_counts)\n",
    "probs  # 문장의 트라이그램 확률 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217267bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'prob': [],\n",
    "       'edit': [],\n",
    "       'lcs': [],\n",
    "        'gleu': [],\n",
    "       'label': [],\n",
    "       'uni':[],\n",
    "       'bi':[],\n",
    "    'tri':[]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"aihub 데이터\"\"\"\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "from soynlp.hangle import jamo_levenshtein\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "import sys\n",
    "\n",
    "hyps = []\n",
    "pred = []\n",
    "scores = []\n",
    "\n",
    "for i in trange(len(source)):\n",
    "    prompt = prompter.generate_prompt('맞춤법에 맞게 수정하세요', source[i])\n",
    "    source_len = len(tokenizer.encode(source[i]))\n",
    "    model, test_loader = accelerator.prepare(model, prompt)\n",
    "    batch = tokenizer(prompt, return_tensors='pt')\n",
    "    ids = batch['input_ids'].to('cuda:0', dtype=torch.long)\n",
    "    masks = batch['attention_mask'].to('cuda:0', dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = accelerator.unwrap_model(model).generate(input_ids=ids,\n",
    "                                                              attention_mask=masks,\n",
    "                                                              num_beams=5,\n",
    "                                                              max_new_tokens=100,\n",
    "                                                              return_dict_in_generate=True, \n",
    "                                                              output_scores=True, \n",
    "                                                              temperature=1,\n",
    "                                                              eos_token_id=tokenizer.eos_token_id,\n",
    "                                                              do_sample=False,\n",
    "                                                           num_return_sequences=5,\n",
    "                                                           repetition_penalty=2.0,\n",
    "                                                          )\n",
    "        \n",
    "        transition_scores = accelerator.unwrap_model(model).compute_transition_scores(outputs.sequences, \n",
    "                                                                 outputs.scores, \n",
    "                                                                 outputs.beam_indices, \n",
    "                                                                 normalize_logits=True)\n",
    "    \n",
    "    input_length = ids.shape[1]\n",
    "\n",
    "    for t in range(5):\n",
    "        sentence = tokenizer.decode(outputs.sequences[t, input_length:], skip_special_tokens=True)\n",
    "        prob = np.exp(outputs.sequences_scores[t].cpu().numpy())\n",
    "        edit = jamo_levenshtein(source[i], sentence)\n",
    "        # LCS\n",
    "        word1, word2 = source[i], sentence\n",
    "        l1, l2 = len(word1), len(word2)\n",
    "        cache = [0] * l2\n",
    "\n",
    "        for j in range(l1):\n",
    "            cnt = 0\n",
    "            for k in range(l2):\n",
    "                if cnt < cache[k]:\n",
    "                    cnt = cache[k]\n",
    "                elif word1[j] == word2[k]:\n",
    "                    cache[k] = cnt + 1\n",
    "        try:\n",
    "            lcs = max(cache)\n",
    "        except:\n",
    "            lcs = 0\n",
    "        # gleu\n",
    "        reference = [source[i].split()]\n",
    "        candidate = sentence.split()\n",
    "        gleu = sentence_gleu(reference, candidate)\n",
    "        \n",
    "        label = 1 if target[i] == sentence else 0\n",
    "        \n",
    "        data['prob'].append(prob)\n",
    "        data['edit'].append(edit)\n",
    "        data['lcs'].append(lcs)\n",
    "        data['gleu'].append(gleu)\n",
    "        data['label'].append(label)\n",
    "        \n",
    "        uni_score, bi_score = 0, 0\n",
    "        tri_score = calculate_trigram_probabilities(sentence, bigram_counts, trigram_counts)\n",
    "        \n",
    "\n",
    "        if len(sentence.split()) > 1:\n",
    "            for a in range(len(sentence.split())):\n",
    "                uni_score += uni_model.score(sentence.split()[a])\n",
    "            for a in range(len(sentence.split())-1):\n",
    "                bi_score += bi_model.score(sentence.split()[a+1], [sentence.split()[a]])\n",
    "\n",
    "            data['uni'].append(uni_score/len(sentence.split()))\n",
    "            data['bi'].append(bi_score/(len(sentence.split())-1))\n",
    "            data['tri'].append(tri_score/len(sentence.split())-2)\n",
    "\n",
    "        else:\n",
    "            uni_score += uni_model.score(sentence)\n",
    "            bi_score += bi_model.score(sentence)\n",
    "\n",
    "            data['uni'].append(uni_score)\n",
    "            data['bi'].append(bi_score)\n",
    "            data['tri'].append(tri_score)\n",
    "            \n",
    "            \n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de650c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c22d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ngram_aihub_tri.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ec895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"ngram_aihub_tri.csv\")\n",
    "data = df[['prob','edit', 'lcs', 'gleu','uni','bi','tri','label']]\n",
    "\n",
    "# scaler = RobustScaler()\n",
    "# std_data = scaler.fit_transform(data.iloc[:,:-1])\n",
    "\n",
    "# df = pd.DataFrame(std_data, columns=data.columns[:-1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f972576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련세트 점수: {:.2f}\".format( model.score(X_train, y_train) ))\n",
    "print(\"테스트세트 점수: {:.2f}\".format( model.score(X_test, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "ax = plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련세트 점수: {:.2f}\".format( model.score(X_train, y_train) ))\n",
    "print(\"테스트세트 점수: {:.2f}\".format( model.score(X_test, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "ax = plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d34db12",
   "metadata": {},
   "source": [
    "# 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"ngram_aihub_tri.csv\")\n",
    "\n",
    "\n",
    "data = data[['prob','edit','lcs','gleu','uni', 'bi', 'tri', 'label']]\n",
    "scaler = StandardScaler()\n",
    "std_data = scaler.fit_transform(data.iloc[:,:-1])\n",
    "\n",
    "columns = ['prob', 'edit', 'lcs', 'gleu', 'uni', 'bi', 'tri']  # Replace with your actual column names\n",
    "df = pd.DataFrame(std_data, columns=columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, data.iloc[:, -1], test_size=0.2, shuffle=False)\n",
    "\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cls = lgb.LGBMClassifier()\n",
    "cls.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련세트 점수: {:.2f}\".format( cls.score(X_train, y_train) ))\n",
    "print(\"테스트세트 점수: {:.2f}\".format( cls.score(X_test, y_test) ))\n",
    "\n",
    "# 특성 중요도를 시각화합니다.\n",
    "lgb.plot_importance(cls, figsize=(10, 6), importance_type='split') # 또는 'gain'을 사용할 수도 있습니다.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae354b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "cls = XGBClassifier()\n",
    "cls.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련세트 점수: {:.2f}\".format( cls.score(X_train, y_train) ))\n",
    "print(\"테스트세트 점수: {:.2f}\".format( cls.score(X_test, y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../ngram/uni_model.pkl', 'rb') as f:\n",
    "    uni_model = pickle.load(f)\n",
    "    \n",
    "with open('../ngram/bi_model.pkl', 'rb') as f:\n",
    "    bi_model = pickle.load(f)\n",
    "    \n",
    "def load_ngram_counts(filename):\n",
    "    \"\"\"\n",
    "    Load bigram and trigram counts from a .pkl file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        bigram_counts, trigram_counts = pickle.load(f)\n",
    "    return bigram_counts, trigram_counts\n",
    "\n",
    "def calculate_trigram_probabilities(sentence, bigram_counts, trigram_counts):\n",
    "    \"\"\"\n",
    "    Calculate trigram probabilities for a given sentence using loaded bigram and trigram counts.\n",
    "    \"\"\"\n",
    "    # 토큰화된 문장 준비\n",
    "    words = sentence.split()\n",
    "    trigram_probabilities = 0\n",
    "\n",
    "    for i in range(len(words) - 2):\n",
    "        trigram = (words[i], words[i + 1], words[i + 2])\n",
    "        bigram = (words[i], words[i + 1])\n",
    "\n",
    "        # 바이그램과 트라이그램 빈도를 사용하여 확률 계산\n",
    "        if trigram in trigram_counts and bigram in bigram_counts:\n",
    "#             trigram_probabilities[trigram] = trigram_counts[trigram] / bigram_counts[bigram]\n",
    "            trigram_probabilities += trigram_counts[trigram] / bigram_counts[bigram]\n",
    "#         else:\n",
    "#             trigram_probabilities[trigram] = 0\n",
    "\n",
    "    return trigram_probabilities\n",
    "\n",
    "bigram_counts, trigram_counts = load_ngram_counts('../ngram/tri_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25803233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForMaskedLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import random\n",
    "\n",
    "# 원하는 시드 값으로 설정\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "## 모델 준비\n",
    "model_id = \"beomi/polyglot-ko-12.8b-safetensors\"  # safetensors 컨버팅된 레포\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#     load_in_8bit=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={'':0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    padding_side=\"left\",\n",
    "    model_max_length=512,    \n",
    ")\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model = PeftModel.from_pretrained(model = model, model_id = './output/SFT_aihub')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from utils.prompter import Prompter\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "prompter = Prompter()\n",
    "\n",
    "with open('SFT_aihub_test.json', 'r', encoding='utf-8-sig') as f:\n",
    "    json_read = json.load(f)\n",
    "\n",
    "source, target = [], []\n",
    "for s in json_read:\n",
    "    source.append(s['input'])\n",
    "    target.append(s['output'])\n",
    "    \n",
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"aihub 데이터\"\"\"\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from soynlp.hangle import jamo_levenshtein\n",
    "from nltk.translate.gleu_score import sentence_gleu\n",
    "\n",
    "hyps = []\n",
    "pred = []\n",
    "scores = []\n",
    "\n",
    "for i in trange(len(source)):\n",
    "    prompt = prompter.generate_prompt('맞춤법에 맞게 수정하세요', source[i])\n",
    "    model, test_loader = accelerator.prepare(model, prompt)\n",
    "    batch = tokenizer(prompt, return_tensors='pt')\n",
    "    ids = batch['input_ids'].to('cuda:0', dtype=torch.long)\n",
    "    masks = batch['attention_mask'].to('cuda:0', dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = accelerator.unwrap_model(model).generate(input_ids=ids,\n",
    "                                                              attention_mask=masks,\n",
    "                                                              num_beams=5,\n",
    "                                                              max_new_tokens=100,\n",
    "                                                              return_dict_in_generate=True, \n",
    "                                                              output_scores=True, \n",
    "                                                              temperature=0.5,\n",
    "                                                              eos_token_id=tokenizer.eos_token_id,\n",
    "#                                                               top_p=False,\n",
    "                                                              do_sample=False,\n",
    "#                                                                 origin_sentence = tokenizer.encode(source[i]),\n",
    "                                                           num_return_sequences=5,\n",
    "#                                                        tokenizer=tokenizer,\n",
    "#                                                        mlm_model=mlm_model,\n",
    "#                                                        mlm_tokenizer=mlm_tokenizer,\n",
    "                                                           )\n",
    "        \n",
    "        transition_scores = accelerator.unwrap_model(model).compute_transition_scores(outputs.sequences, \n",
    "                                                                 outputs.scores, \n",
    "                                                                 outputs.beam_indices, \n",
    "                                                                 normalize_logits=True)\n",
    "\n",
    "    input_length = ids.shape[1]\n",
    "    preds = \"\"\n",
    "    probabilities = {}\n",
    "    for t in range(5):\n",
    "        sentence = tokenizer.decode(outputs.sequences[t, input_length:], skip_special_tokens=True)\n",
    "        prob = np.exp(outputs.sequences_scores[t].cpu().numpy())\n",
    "        edit = jamo_levenshtein(source[i], sentence)\n",
    "        # LCS\n",
    "        word1, word2 = source[i], sentence\n",
    "        l1, l2 = len(word1), len(word2)\n",
    "        cache = [0] * l2\n",
    "\n",
    "        for j in range(l1):\n",
    "            cnt = 0\n",
    "            for k in range(l2):\n",
    "                if cnt < cache[k]:\n",
    "                    cnt = cache[k]\n",
    "                elif word1[j] == word2[k]:\n",
    "                    cache[k] = cnt + 1\n",
    "        try:\n",
    "            lcs = max(cache)\n",
    "        except:\n",
    "            lcs = 0\n",
    "        # gleu\n",
    "        reference = [source[i].split()]\n",
    "        candidate = sentence.split()\n",
    "        gleu = sentence_gleu(reference, candidate)\n",
    "        \n",
    "        uni_score, bi_score = 0, 0\n",
    "        tri_score = calculate_trigram_probabilities(sentence, bigram_counts, trigram_counts)\n",
    "        if len(sentence.split()) > 2:\n",
    "            for a in range(len(sentence.split())):\n",
    "                uni_score += uni_model.score(sentence.split()[a])\n",
    "            for a in range(len(sentence.split())-1):\n",
    "                bi_score += bi_model.score(sentence.split()[a+1], [sentence.split()[a]])\n",
    "                \n",
    "            uni = uni_score / len(sentence.split())\n",
    "            bi = bi_score / (len(sentence.split())-1)\n",
    "            tri = tri_score/(len(sentence.split())-2)\n",
    "\n",
    "        else:\n",
    "            uni = uni_model.score(sentence)\n",
    "            bi = bi_model.score(sentence)\n",
    "            \n",
    "        feature = np.array([[prob, edit, lcs, gleu, uni, bi, tri]])\n",
    "        feature = scaler.transform(feature)\n",
    "\n",
    "        predict = cls.predict_proba(feature)[0]\n",
    "        probabilities[t] = predict[1]\n",
    "    probabilities = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    preds = tokenizer.decode(outputs.sequences[probabilities[0][0], input_length:])\n",
    "    pred.append(preds.replace(\"<|endoftext|>\", \"\").replace('<|unused0|>', ''))\n",
    "pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9efc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df = pd.DataFrame({'pred':pred})\n",
    "pred.to_csv('all_xbg_pred_tri.csv', index=False, header=False)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# pred = pd.read_csv('all_xbg_pred.csv', header=None, names=['pred'])\n",
    "total = len(pred)\n",
    "correct_pred, correct_hyp = 0, 0\n",
    "wrong_hyp_df, correct_hyp_df = pd.DataFrame(), pd.DataFrame()\n",
    "sources, targets, preds = [],[], []\n",
    "len_sources, len_targets, len_preds = [], [], []\n",
    "count = 0\n",
    "\n",
    "for i in range(total):\n",
    "    is_correct = False\n",
    "    pred[0][i] = pred[0][i].replace(\"<|endoftext|>\",\"\").replace(\"<|unused0|>\", \"\").strip()\n",
    "    \n",
    "    target_cleaned = re.sub(r'[^\\w\\s]', '', target[i]).strip()\n",
    "    pred_cleaned = re.sub(r'[^\\w\\s]', '', pred[0][i]).strip()\n",
    "            \n",
    "    if target[i] == pred[0][i]:\n",
    "        correct_pred += 1\n",
    "#     else:\n",
    "#         print(pred[0][i], \"|\", target[i])\n",
    "    \n",
    "\n",
    "        \n",
    "print(f\"pred acc:{correct_pred}/{total} = {correct_pred/total}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
